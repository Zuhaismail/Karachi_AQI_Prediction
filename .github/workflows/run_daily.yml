name: Run AQI Pipeline Daily

on:
  schedule:
    # Run every day at 12:00 PM Karachi time (UTC+5 = 07:00 UTC)
    - cron: "0 7 * * *"
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    env:
      AQI_API_KEY: ${{ secrets.AQI_API_KEY }}

    steps:
      # 1. Checkout repo
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2. Setup Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      # 3. Install dependencies (no requirements.txt needed)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy matplotlib scikit-learn lightgbm streamlit requests python-dotenv

      # 4. Run scripts in sequence
      - name: Run API parser
        run: python api_parser.py

      - name: Run feature engineering
        run: python feature_engineering.py

      - name: Run data preprocessing
        run: python data_Preprocessing.py

      - name: Train models
        run: python train_models.py

      - name: Generate forecast
        run: python forecast.py

      - name: Update Streamlit app
        run: python app.py

        # 5. Commit & push updated CSVs + model
      - name: Commit and push updated data & model
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add forecast_next3days_all_models.csv \
                 karachi_aqi_features.csv \
                 karachi_air_quality.csv \
                 model_results.csv 
          git commit -m "Auto-update AQI data, forecasts & model [skip ci]" || echo "No changes to commit"
          git push
